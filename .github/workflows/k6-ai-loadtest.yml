name: K6 Local Load Test + AI Interpretation

on:
  workflow_dispatch:
    inputs:
      target_url:
        description: "Target base URL (backend Container App)"
        required: true
        default: "https://skycastnow-backend.yellowmoss-69428b58.westeurope.azurecontainerapps.io"

jobs:
  loadtest:
    runs-on: ubuntu-latest

    permissions:
      id-token: write
      contents: read

    env:
      ARM_USE_OIDC: true
      ARM_CLIENT_ID: ${{ secrets.AZURE_CLIENT_ID }}
      ARM_TENANT_ID: ${{ secrets.AZURE_TENANT_ID }}
      ARM_SUBSCRIPTION_ID: ${{ secrets.AZURE_SUBSCRIPTION_ID }}

      RG: rg-skycastnow
      APP: skycastnow-backend
      POLL_INTERVAL_JSON: 10
      POLL_INTERVAL_TABLE: 30
      POLL_INTERVAL_METRICS: 60

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Azure Login (OIDC)
        uses: azure/login@v2
        with:
          client-id: ${{ secrets.AZURE_CLIENT_ID }}
          tenant-id: ${{ secrets.AZURE_TENANT_ID }}
          subscription-id: ${{ secrets.AZURE_SUBSCRIPTION_ID }}

      - name: Run k6 and capture scaling + metrics
        env:
          TARGET_URL: ${{ github.event.inputs.target_url }}
        run: |
          set -euo pipefail

          echo "==> Initializing output files"
          : > replicas.ndjson
          : > replicas-table.log
          : > metrics.ndjson

          cleanup() {
            echo "==> Cleaning up pollers"
            [[ -n "${JSON_POLLER_PID:-}" ]] && kill "${JSON_POLLER_PID}" || true
            [[ -n "${TABLE_POLLER_PID:-}" ]] && kill "${TABLE_POLLER_PID}" || true
            [[ -n "${METRICS_POLLER_PID:-}" ]] && kill "${METRICS_POLLER_PID}" || true
            wait || true
          }
          trap cleanup EXIT

          RESOURCE_ID="$(az containerapp show -g "${RG}" -n "${APP}" --query id -o tsv)"
          ENV_ID="$(az containerapp show -g "${RG}" -n "${APP}" --query environmentId -o tsv)"
          ENV_NAME="$(basename "${ENV_ID}")"

          LAW_ID="$(az containerapp env show \
            -g "${RG}" \
            -n "${ENV_NAME}" \
            --query appLogsConfiguration.logAnalyticsConfiguration.customerId \
            -o tsv)"

          poll_replicas_json() {
            while true; do
              TS="$(date -u +"%Y-%m-%dT%H:%M:%SZ")"
              REPLICAS_JSON="$(az containerapp replica list -g "${RG}" -n "${APP}" -o json 2>/dev/null || echo "[]")"
              COUNT="$(echo "${REPLICAS_JSON}" | jq length 2>/dev/null || echo 0)"
              echo "{\"ts\":\"${TS}\",\"replicaCount\":${COUNT},\"replicas\":${REPLICAS_JSON}}" >> replicas.ndjson
              sleep "${POLL_INTERVAL_JSON}"
            done
          }

          poll_replicas_table() {
            while true; do
              TS="$(date -u +"%Y-%m-%dT%H:%M:%SZ")"
              {
                echo ""
                echo "===== ${TS} ====="
                az containerapp replica list -g "${RG}" -n "${APP}" -o table || true
              } >> replicas-table.log
              sleep "${POLL_INTERVAL_TABLE}"
            done
          }

          poll_metrics() {
            while true; do
              TS="$(date -u +"%Y-%m-%dT%H:%M:%SZ")"

              read -r -d '' QUERY <<EOF
          ContainerAppConsoleLogs_CL
          | where ContainerAppName_s == "${APP}"
          | summarize
              cpu_avg = avg(todouble(CpuUsage_s)),
              cpu_max = max(todouble(CpuUsage_s)),
              mem_avg = avg(todouble(MemoryWorkingSetBytes_s)),
              mem_max = max(todouble(MemoryWorkingSetBytes_s))
            by bin(TimeGenerated, 1m)
          | order by TimeGenerated desc
          | take 5
          EOF

              METRICS_JSON="$(az monitor log-analytics query \
                --workspace "${LAW_ID}" \
                --analytics-query "${QUERY}" \
                -o json 2>/dev/null || echo "{}")"

              echo "{\"ts\":\"${TS}\",\"logAnalytics\":${METRICS_JSON}}" >> metrics.ndjson
              sleep "${POLL_INTERVAL_METRICS}"
            done
          }

          echo "==> Starting Azure pollers"
          poll_replicas_json & JSON_POLLER_PID=$!
          poll_replicas_table & TABLE_POLLER_PID=$!
          poll_metrics & METRICS_POLLER_PID=$!

          echo "==> Running k6 load test"
          set +e
          docker run --rm \
            --user root \
            -e TARGET_URL="${TARGET_URL}" \
            -v "${{ github.workspace }}:/scripts" \
            grafana/k6 \
            run /scripts/weather-cities-scale-test.js \
            --summary-export=/scripts/summary.json
          K6_EXIT_CODE=$?
          set -e

          echo "==> k6 exit code: ${K6_EXIT_CODE}"
          ls -lh summary.json replicas.ndjson replicas-table.log metrics.ndjson || true

      - name: Interpret k6 + scaling + metrics with OpenAI
        env:
          OPENAI_API_KEY: ${{ secrets.OPEN_AI_KEY }}
        run: |
          node scripts/analyze-k6-ai.mjs \
            summary.json \
            replicas.ndjson \
            metrics.ndjson \
            | tee ai_report.md
      
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: 20

      - name: Generate autoscaling graphs
        run: |
          npm install chartjs-node-canvas --no-save
          node scripts/plot-autoscaling.mjs

      - name: Upload k6 AI artifacts
        uses: actions/upload-artifact@v4
        with:
          name: k6-ai-analysis
          path: |
            summary.json
            replicas.ndjson
            replicas-table.log
            metrics.ndjson
            ai_report.md
            replicas.png
            resources.png